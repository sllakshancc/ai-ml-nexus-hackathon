{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf283e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pandas numpy scikit-learn joblib streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cuml-cu12 --index-url=https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874557b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "def load_first_tabular_file(dataset_name):\n",
    "    # Download the entire dataset (or at least one supported file)\n",
    "    path = kagglehub.dataset_download(dataset_name, force_download=True)\n",
    "    # The `path` returns the directory or file path where data has been placed.\n",
    "\n",
    "    # Then you can manually inspect the downloaded path, search for supported extensions\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    supported_exts = [\".csv\", \".tsv\", \".json\", \".jsonl\", \".parquet\",\n",
    "                      \".xls\", \".xlsx\", \".xlsm\", \".xlsb\", \".ods\"]\n",
    "    # Walk the path to find a suitable file\n",
    "    file_to_load = None\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            _, ext = os.path.splitext(f)\n",
    "            if ext.lower() in supported_exts:\n",
    "                file_to_load = os.path.join(root, f)\n",
    "                break\n",
    "        if file_to_load:\n",
    "            break\n",
    "\n",
    "    if file_to_load is None:\n",
    "        raise ValueError(f\"No supported tabular file found in dataset '{dataset_name}'\")\n",
    "\n",
    "    df = pd.read_csv(file_to_load)  # adjust if needed for e.g. Excel\n",
    "    return df\n",
    "\n",
    "dataset_name = \"shanegerami/ai-vs-human-text\"\n",
    "complete_data_set = load_first_tabular_file(dataset_name)\n",
    "\n",
    "print(\"Columns:\", complete_data_set.columns.tolist())\n",
    "print(\"First 5 records:\")\n",
    "print(complete_data_set.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb30a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = complete_data_set.sample(n=100, replace=False, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Check columns\n",
    "print(\"Columns in df:\", data.columns.tolist())\n",
    "\n",
    "# Make sure 'generated' and 'text' exist\n",
    "if \"generated\" in data.columns and \"text\" in data.columns:\n",
    "\n",
    "    def get_random_text(label):\n",
    "        \"\"\"\n",
    "        Get a random text for a given label.\n",
    "        label: 0 for human, 1 for AI\n",
    "        \"\"\"\n",
    "        subset = data[data[\"generated\"] == label]\n",
    "        if len(subset) == 0:\n",
    "            return f\"No texts found for label {label}\"\n",
    "        return subset[\"text\"].sample(n=1).iloc[0]\n",
    "\n",
    "    # Example usage\n",
    "    random_human_text = get_random_text(0)\n",
    "    random_ai_text = get_random_text(1)\n",
    "\n",
    "    print(\"Random human text:\", random_human_text)\n",
    "    print(\"\\n\\nRandom AI text:\", random_ai_text)\n",
    "\n",
    "else:\n",
    "    print(\"'generated' or 'text' column not found in the DataFrame\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
